# 🚀 实习日志 | 第二周

> **实习时间**：2025年12月8日（周一）- 12月12日（周五）
> **研究方向**：大规模 Schema 下的 Text-to-SQL 多表关联推理
> **指导方向**：AI 算法实习

---

## 📅 第二周工作概览

### 12月8日 周一 | LinkAlign 方案落地探索

**今日工作**

- 开始研读 **LinkAlign** 论文源码
- 搭建 LinkAlign 本地开发环境
- 学习项目的核心架构：多轮语义增强检索 + Schema Item Grounding
- 继续阅读其他相关论文

**论文阅读**

- **Text-to-SQL Multi-table Join Prediction and Schema**: 多表关联预测方法
- **(arXiv:2505.18744)**: 相关检索增强方法

**技术架构**

1. Draft Retrieval：使用向量检索获取 Top-K 候选表
2. Schema Audit：LLM 审计检索结果的完整性
3. Query Rewriting：生成包含 Schema 关键词的增强查询
4. Final Retrieval：二次检索补全遗漏的表

**收获与思考**

从今天开始，我要从"读论文"转向"复现论文"了。这个转变让我意识到，学术界和业界是不一样的。论文里写得很漂亮的方法，真正落地的时候会遇到各种问题。

论文里的实验环境、数据集、超参数配置，都和我们实际的业务场景不一样。他们用的是 Spider 2.0 数据集，我们要接的是真实的业务数据库，光是表数量就有344张，列数量超过3000个。这种规模差异会带来很多挑战。

---

### 12月9日 周二 | 环境配置与数据准备

**今日工作**

- 完成 LinkAlign 项目的本地环境配置
- 配置 Python 虚拟环境，安装依赖（LlamaIndex, sentence-transformers 等）
- 修改 LlamaIndex 源码以适配项目需求
- 编写 MySQL Schema 提取脚本，成功提取业务数据库的 344 张表、3353 个列

**技术细节**

- 使用 Qwen3-14B-awq 作为本地 LLM
- 使用 BGE-large-en-v1.5 作为 Embedding 模型
- 编写 `extract_mysql_schema.py` 脚本提取真实业务数据库的 Schema

**收获与思考**

配环境永远是最折腾的环节。今天花了大半天在处理依赖冲突、网络问题、模型下载等琐事上。但看到 Qwen API 测试通过、Schema 成功提取的那一刻，还是挺有成就感的。

---

### 12月10日 周三 | Schema Linking 测试与优化

**今日工作**

- 运行 LinkAlign Schema Linking 测试
- 编写 `test_optimization.py`：对比不同模式（Agent / Pipeline）和参数（top_k, turn_n）的效果
- 编写 `test_query_expansion.py`：实现查询扩展机制，解决中英文混合检索问题
- 分析检索结果，评估召回率和精确率

**优化方案**

- 实现了跨语言查询扩展：将中文查询扩展为包含英文关键词的增强查询
- 对比了多种检索策略的效果

**核心发现**

- Agent 模式在复杂查询上表现更好，但耗时更长
- 查询扩展能显著提升中英文混合 Schema 的检索召回率
- similarity_top_k 和 turn_n 参数的调优对精确率影响很大

**收获与思考**

今天的测试让我深刻体会到了论文落地的困难。论文中报告的指标是在标准数据集上得到的，但我们的真实业务数据库有很多"脏"的地方：表名是英文、备注是中文、字段命名不规范等等。

用户问"告警"，但表名是 `event_history`；用户问"客户"，但表名是 `t_bz_config_customer`。这种语义鸿沟在论文里不会提到，但在实际落地中是必须解决的。

于是我写了一个查询扩展模块，让LLM在检索之前先把中文翻译成各种可能的英文变体。效果确实有提升，但离理想状态还有差距。这大概就是科研和工程的区别吧。

---

### 12月11日 周四 | 深入理解 LinkAlign & 帮同事 Debug

**今日工作**

- 继续测试 LinkAlign，深入理解其核心机制
- 帮助同事 debug 一个语音对话项目的人机切换功能

**LinkAlign 的真正理解**

今天继续测试 LinkAlign，我发现我之前没有真正理解它在干什么。我之前还以为它的操作是两个 LLM 互相对话，然后得出最优的 SQL，实际上完全不是——它用的是自己的向量检索器进行 Schema Linking，然后再交给 LLM 生成 SQL。我人都傻了，都怪我，没有真正理解论文。

我配合 AI 去阅读论文，但 Gemini 3 Pro 可能幻觉比较高，误导了我对论文核心机制的理解。反思了一下：面对这种专业的、超长的论文，如果完全不依赖 AI，那么研究速度确实会非常慢；但如果不把问题研究清楚就开始动手，之后只会花更多的时间来改。有点两难。

接下来需要更仔细地研究每篇论文的具体操作，不能只看大概架构。继续尝试更多的测试数据。

**额外任务**

同一个办公室的同事让我帮忙解决一个问题。他的项目是做语音对话的情绪识别——当检测到对面有负面情绪时，自动接通人工客服。这个项目全部是用 AI 写的，但最后人机切换的功能一直有问题，无法正确触发。

我用 AI 一步一步地去分析代码、写测试、定位问题。最后发现是 JavaScript 里的作用域问题——一个变量在回调函数里没有正确绑定 `this`。

我自己对 JavaScript 其实不太熟，前端三大件都是很早期自学的，并不规范。但在 AI 的帮助下，我还是把问题解决了。

**收获与思考**

今天有两个很深的感悟：

**关于论文阅读：** AI 辅助读论文是把双刃剑。它确实能加速理解，但如果 AI 给出的解读有误（幻觉），你可能会走很多弯路。核心的技术细节还是要自己去抠论文原文，不能完全依赖 AI 的总结。

**关于帮同事 Debug：** 作为一个实习生，为什么能够完成一个正式员工都没解决的问题？我觉得第一是我更会使用 AI——让 AI 一步一步地分析问题，而不是一次性丢给它一个大问题。先让 AI 读代码理解架构，再让它针对特定功能写测试用例，最后根据测试结果逐步缩小问题范围。第二是心态，很多时候不是问题有多难，而是有没有耐心去一步步排查。

---

### 12月12日 周五 | LinkAlign 深度分析与优化尝试

**今日工作**

- 对 LinkAlign 进行深度分析和优化尝试
- SQL 对比分析：分析 7 个测试用例，对比 LinkAlign 生成的 SQL 与正确 SQL
- 根因定位：发现 Schema 元数据（列描述）50% 缺失的问题
- 设计和实现 Schema 自动增强方案
- 修改 SQL 生成的 Prompt 模板
- 验证测试并定位到更深层的算法问题

**SQL 对比分析**

详细对比分析每个测试用例的 SQL 生成结果：
- SQL 正确率：0/7 (0%)
- 错误原因：
  - 表名选择错误（如使用 `report_new_dev` 而非 `t_bz_config_ci_ne_root`）
  - 强制 JOIN 导致无意义关联
  - LLM 输出包含大量 `<think>` 标签

**根因定位**

检查 Schema 文件时发现两大问题：

1. **Schema 元数据缺失**：
   - 检查了 `extract_mysql_schema.py` 源码
   - 确认 schema 是从 MySQL 数据库的 `COLUMN_COMMENT` 提取
   - 统计结果：3353 个列中，1679 个（50%）描述为 null
   - LinkAlign 不自带 schema 生成工具，论文测试用的是高质量公开数据集（Spider/BIRD）

2. **Prompt 模板不合理**：
   - 原 Prompt 强制要求使用 JOIN 关联多个表
   - 简单查询不需要强制 JOIN

**Schema 自动增强方案**

设计思路：如果数据库列没有注释，就用 LLM 基于列名、类型、样本数据自动生成描述

实现内容：
- 创建 `extract_mysql_schema_enhanced.py` 全量增强版
- 创建 `enhance_core_tables.py` 核心表快速增强版
- 优化 Prompt，明确禁止思考过程
- 添加响应清理函数，去除 `<think>` 标签等噪音

测试效果：
- 3 个核心表：`t_bz_config_ci_ne_root`、`t_bz_config_customer`、`event_history`
- 处理 155 列，LLM 生成 34 个描述

**SQL Prompt 优化**

```diff
- 【要求】使用JOIN关联多个表
+ 【规则】根据问题复杂度决定是否使用 JOIN（简单查询不需要强制 JOIN）
+ 【规则】直接输出 SQL，不要任何思考过程或解释
```

**验证测试与关键发现**

测试用例 5："上个月上线的新设备有多少"

| 阶段 | 结果 |
|:-----|:-----|
| 向量检索 | ✅ 找到 `t_bz_config_ci_ne_root` |
| Reserve 保护 | ⚠️ 未进入保护列表 |
| LLM 过滤轮次1 | ❌ 被过滤掉（142表→53表）|
| 表召回率 | 0% |

**意外发现：不是 Schema 描述的问题，而是 LinkAlign 的过滤算法缺陷！**

LinkAlign 按列投票判断表是否相关：
```
t_bz_config_ci_ne_root (75列):
  - ONLINE_TIME: 相关 ✅
  - 其他74列: 不相关 ❌
  
投票结果: 1/75 = 1.3%
判定: 过滤掉整个表 ❌
```

应该的逻辑：只要有一个关键列相关 → 保留整表

**技术产出**

- `extract_mysql_schema_enhanced.py` - 全量增强版
- `enhance_core_tables.py` - 核心表快速增强版
- `quick_validate.py` - 单用例快速验证脚本
- `sql_analysis_report.md` - SQL 对比分析报告
- `validation_report.md` - Schema 增强验证报告

**收获与思考**

今天的工作体现了完整的问题解决流程：

1. **问题导向的研究方法**：现象观察 → 初步分析 → 假设提出 → 验证实验 → 推翻假设 → 深入挖掘 → 新假设

2. **学术 vs 工程的差距**：论文关注理想条件下的算法创新，工程需要处理真实世界的复杂性和不完美数据。桥接这个差距需要大量的适配和优化工作。

3. **Schema 增强没有解决问题**：我以为是 Schema 描述缺失导致的，花了 2 个小时实现增强方案，结果发现问题出在更深层的过滤算法逻辑上。这是个很好的教训——要先确认根本原因，再动手实现解决方案。

---

## 💭 第二周感悟

### 关于AI与未来

对比我去年的实习，现在的 AI 强大太多了。我和上个实习的导师聊天时，他说："如果 AI 的发展继续保持两年，之后开发就要被淘汰了。现在 2-3 个开发配合 AI 就能完成一个项目，以后 3 个项目一个开发配合 AI 就足够了。"

AI 的发展让我学习计算机变得非常轻松，它就是一个 24 小时随叫随到的老师。但同时，AI 的发展也在挤压程序员未来的生存空间。

我本来是想走后端开发、全栈开发的路线的，但随着 AI 的发展，我觉得我需要转向 AI 算法相关的方向——不是放弃开发，而是做 AI 项目的开发、AI 算法的工程落地。

我非常感谢能够在本科阶段获得这个算法实习机会。确定这个方向，对我来说非常重要。

---

## 📚 本周论文清单

| 序号 | 论文                                                       | 核心贡献                                                |
| :--: | :--------------------------------------------------------- | :------------------------------------------------------ |
|  1  | **Text-to-SQL Multi-table Join Prediction**          | 多表关联预测与Schema分析                                |
|  2  | **(arXiv:2505.18744)**                               | 检索增强相关方法                                        |

---

> *"学术界和业界是不一样的——论文写得很漂亮，落地的时候挑战才刚刚开始。"*
