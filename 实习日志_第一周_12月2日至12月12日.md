# 🚀 实习日志 | 第一周

> **实习时间**：2024年12月2日（周一）- 12月12日（周四）
> **研究方向**：大规模 Schema 下的 Text-to-SQL 多表关联推理
> **指导方向**：AI 算法实习

---

## 📅 第一周工作概览

### 12月2日 周一 | 入职熟悉

**今日工作**

- 抵达公司，开始熟悉工作环境
- 与导师进行初次交流，了解研究方向
- 获取项目资料，开始了解 Text-to-SQL 任务的背景

**收获与思考**

今天是我来公司的第一天，虽然正式入职要到周四，但我已经迫不及待地想要开始学习了。导师给我介绍了研究方向——Text-to-SQL多表关联推理，这是一个把自然语言转换为SQL查询的任务，听起来非常有意思。

---

### 12月3日 周二 | 论文阅读启动

**今日工作**

- 开始阅读 Text-to-SQL 领域的核心论文
- 学习了解 Spider、BIRD 等标准评测数据集
- 初步理解"规模墙"问题：当数据库表数量超过100张时，LLM准确率从86%断崖式下跌至5%

**论文阅读**

1. **CHESS** (arXiv:2405.16755): Contextual Harnessing for Efficient SQL Synthesis - 多智能体协作框架
2. **Using LLMs for Multi-hop Reasoning** (arXiv:2405.09593): 利用大语言模型进行多跳推理

**收获与思考**

今天开始正式读论文了。说实话，这是我第一次系统性地阅读arxiv上的前沿论文，之前在学校虽然也读过论文，但那种感觉完全不一样。这些论文都是非常新的，有些甚至还没来得及发到顶会或期刊，我感觉我确实接触到了世界上最先进的东西。

读完第一篇论文之后，我发现其实在AI的帮助下，绝大部分论文都能理解并且读懂。我之前以为算法领域会非常高深莫测，但实际上，论文的核心创新点往往是现有算法的组合与改进，而不是完全从无到有的发明创造。这让我对未来如果要读研究性硕士或者PhD的"科研"有了更清晰的认识。

---

### 12月4日 周三 | 深入研究图算法方案

**今日工作**

- 深入阅读 **SteinerSQL** 论文：基于图拓扑约束的Text-to-SQL方法
- 学习论文中提出的斯坦纳树（Steiner Tree）算法在Schema Linking中的应用
- 阅读 **SchemaGraphSQL**：基于图寻路的高效Schema Linking方法
- 理解多维代价函数与图遍历算法的结合

**核心论文**

- **SteinerSQL** (arXiv:2509.19623): Graph-Guided Mathematical Reasoning for Text-to-SQL Generation
- **SchemaGraphSQL** (arXiv:2505.18363): Efficient Schema Linking with Pathfinding Graph Algorithms

**技术要点**

- Schema Graph 构建：将数据库Schema建模为加权无向图 G=(V, E, C)
- 多维代价函数：C_total = α·C_connect + β·C_sem + γ·C_stat
- 终端节点映射：通过数学分解识别查询所需的关键表

**收获与思考**

今天读到了一些使用图论思想解决问题的论文。SteinerSQL论文中提出了使用**Steiner Tree**算法来解决Schema Linking问题——把数据库表抽象成图上的节点，把外键关系抽象成边，然后用最小生成树相关的算法找到连接所有关键表的最优路径。

这让我想起了墨尔本大学上个月教给我的图论课程。虽然论文里用的是Steiner Tree这个具体的算法，但背后的图论思想——把复杂的关系建模成图，然后用图算法找到最优解——是我在学校里系统学过的。

说实话，我之前一直抱怨墨大的课程对找工作没有帮助，因为学校不提供校招，课程内容也感觉离工业界太远。但今天看到这些论文的时候，我意识到学校教的东西不是没用，是当时的我不知道它能用在哪里。图的遍历、最短路径、最小生成树这些概念，原来在AI算法落地的时候真的能派上用场。

---

### 12月5日 周四 | 正式入职 & 组会汇报

**今日工作**

- **正式入职**，办理入职手续
- 继续阅读论文：UNJOIN、LinkAlign
- 参加组会，进行 Text-to-SQL 研究汇报

**论文阅读**

- **UNJOIN** (arXiv:2505.18122): Enhancing Multi-Table Text-to-SQL Generation via Schema Simplification
- **LinkAlign** (arXiv:2503.18596): Scalable Schema Linking for Real-World Large-Scale Multi-Database Text-to-SQL

**汇报内容**

- 介绍了"规模墙"问题及三大核心挑战：语义检索盲区、拓扑幻觉、数学逻辑与Schema的割裂
- 详细讲解了 SteinerSQL 的图算法引擎
- 综述了 LinkAlign 语义对齐、UNJOIN 模式简化等辅助技术

**收获与思考**

今天终于正式入职了！下午的组会汇报让我有点紧张，但整体上还是顺利完成了。导师对我的研究综述还算满意，提出了一些后续落地的方向。

组会上我展示了这些论文的核心技术，从问题分析到解决方案，再到实验数据。准备这个汇报的过程让我对这些技术有了更系统的理解，也让我意识到，把论文读懂是一回事，能把它讲清楚又是另一回事。

---

### 12月6日 周五 | LinkAlign 方案落地探索

**今日工作**

- 开始研读 **LinkAlign** 论文源码
- 搭建 LinkAlign 本地开发环境
- 学习项目的核心架构：多轮语义增强检索 + Schema Item Grounding
- 继续阅读其他相关论文

**论文阅读**

- **Text-to-SQL Multi-table Join Prediction and Schema**: 多表关联预测方法
- **(arXiv:2505.18744)**: 相关检索增强方法

**技术架构**

1. Draft Retrieval：使用向量检索获取 Top-K 候选表
2. Schema Audit：LLM 审计检索结果的完整性
3. Query Rewriting：生成包含 Schema 关键词的增强查询
4. Final Retrieval：二次检索补全遗漏的表

**收获与思考**

从今天开始，我要从"读论文"转向"复现论文"了。这个转变让我意识到，学术界和业界是不一样的。论文里写得很漂亮的方法，真正落地的时候会遇到各种问题。

论文里的实验环境、数据集、超参数配置，都和我们实际的业务场景不一样。他们用的是 Spider 2.0 数据集，我们要接的是真实的业务数据库，光是表数量就有344张，列数量超过3000个。这种规模差异会带来很多挑战。

---

### 12月9日 周一 | 环境配置与数据准备

**今日工作**

- 完成 LinkAlign 项目的本地环境配置
- 配置 Python 虚拟环境，安装依赖（LlamaIndex, sentence-transformers 等）
- 修改 LlamaIndex 源码以适配项目需求
- 编写 MySQL Schema 提取脚本，成功提取业务数据库的 344 张表、3353 个列

**技术细节**

- 使用 Qwen3-14B-awq 作为本地 LLM
- 使用 BGE-large-en-v1.5 作为 Embedding 模型
- 编写 `extract_mysql_schema.py` 脚本提取真实业务数据库的 Schema

**收获与思考**

配环境永远是最折腾的环节。今天花了大半天在处理依赖冲突、网络问题、模型下载等琐事上。但看到 Qwen API 测试通过、Schema 成功提取的那一刻，还是挺有成就感的。

---

### 12月10日 周二 | Schema Linking 测试与优化

**今日工作**

- 运行 LinkAlign Schema Linking 测试
- 编写 `test_optimization.py`：对比不同模式（Agent / Pipeline）和参数（top_k, turn_n）的效果
- 编写 `test_query_expansion.py`：实现查询扩展机制，解决中英文混合检索问题
- 分析检索结果，评估召回率和精确率

**优化方案**

- 实现了跨语言查询扩展：将中文查询扩展为包含英文关键词的增强查询
- 对比了多种检索策略的效果

**核心发现**

- Agent 模式在复杂查询上表现更好，但耗时更长
- 查询扩展能显著提升中英文混合 Schema 的检索召回率
- similarity_top_k 和 turn_n 参数的调优对精确率影响很大

**收获与思考**

今天的测试让我深刻体会到了论文落地的困难。论文中报告的指标是在标准数据集上得到的，但我们的真实业务数据库有很多"脏"的地方：表名是英文、备注是中文、字段命名不规范等等。

用户问"告警"，但表名是 `event_history`；用户问"客户"，但表名是 `t_bz_config_customer`。这种语义鸿沟在论文里不会提到，但在实际落地中是必须解决的。

于是我写了一个查询扩展模块，让LLM在检索之前先把中文翻译成各种可能的英文变体。效果确实有提升，但离理想状态还有差距。这大概就是科研和工程的区别吧。

---

### 12月11日 周三 | 深入理解 LinkAlign & 帮同事 Debug

**今日工作**

- 继续测试 LinkAlign，深入理解其核心机制
- 帮助同事 debug 一个语音对话项目的人机切换功能

**LinkAlign 的真正理解**

今天继续测试 LinkAlign，我发现我之前没有真正理解它在干什么。我之前还以为它的操作是两个 LLM 互相对话，然后得出最优的 SQL，实际上完全不是——它用的是自己的向量检索器进行 Schema Linking，然后再交给 LLM 生成 SQL。我人都傻了，都怪我，没有真正理解论文。

我配合 AI 去阅读论文，但 Gemini 3 Pro 可能幻觉比较高，误导了我对论文核心机制的理解。反思了一下：面对这种专业的、超长的论文，如果完全不依赖 AI，那么研究速度确实会非常慢；但如果不把问题研究清楚就开始动手，之后只会花更多的时间来改。有点两难。

接下来需要更仔细地研究每篇论文的具体操作，不能只看大概架构。继续尝试更多的测试数据。

**额外任务**

同一个办公室的同事让我帮忙解决一个问题。他的项目是做语音对话的情绪识别——当检测到对面有负面情绪时，自动接通人工客服。这个项目全部是用 AI 写的，但最后人机切换的功能一直有问题，无法正确触发。

我用 AI 一步一步地去分析代码、写测试、定位问题。最后发现是 JavaScript 里的作用域问题——一个变量在回调函数里没有正确绑定 `this`。

我自己对 JavaScript 其实不太熟，前端三大件都是很早期自学的，并不规范。但在 AI 的帮助下，我还是把问题解决了。

**收获与思考**

今天有两个很深的感悟：

**关于论文阅读：** AI 辅助读论文是把双刃剑。它确实能加速理解，但如果 AI 给出的解读有误（幻觉），你可能会走很多弯路。核心的技术细节还是要自己去抠论文原文，不能完全依赖 AI 的总结。

**关于帮同事 Debug：** 作为一个实习生，为什么能够完成一个正式员工都没解决的问题？我觉得第一是我更会使用 AI——让 AI 一步一步地分析问题，而不是一次性丢给它一个大问题。先让 AI 读代码理解架构，再让它针对特定功能写测试用例，最后根据测试结果逐步缩小问题范围。第二是心态，很多时候不是问题有多难，而是有没有耐心去一步步排查。

---

### 12月12日 周四 | LinkAlign 深度分析与优化尝试

**今日工作**

- 对 LinkAlign 进行深度分析和优化尝试
- SQL 对比分析：分析 7 个测试用例，对比 LinkAlign 生成的 SQL 与正确 SQL
- 根因定位：发现 Schema 元数据（列描述）50% 缺失的问题
- 设计和实现 Schema 自动增强方案
- 修改 SQL 生成的 Prompt 模板
- 验证测试并定位到更深层的算法问题

**SQL 对比分析**

详细对比分析每个测试用例的 SQL 生成结果：
- SQL 正确率：0/7 (0%)
- 错误原因：
  - 表名选择错误（如使用 `report_new_dev` 而非 `t_bz_config_ci_ne_root`）
  - 强制 JOIN 导致无意义关联
  - LLM 输出包含大量 `<think>` 标签

**根因定位**

检查 Schema 文件时发现两大问题：

1. **Schema 元数据缺失**：
   - 检查了 `extract_mysql_schema.py` 源码
   - 确认 schema 是从 MySQL 数据库的 `COLUMN_COMMENT` 提取
   - 统计结果：3353 个列中，1679 个（50%）描述为 null
   - LinkAlign 不自带 schema 生成工具，论文测试用的是高质量公开数据集（Spider/BIRD）

2. **Prompt 模板不合理**：
   - 原 Prompt 强制要求使用 JOIN 关联多个表
   - 简单查询不需要强制 JOIN

**Schema 自动增强方案**

设计思路：如果数据库列没有注释，就用 LLM 基于列名、类型、样本数据自动生成描述

实现内容：
- 创建 `extract_mysql_schema_enhanced.py` 全量增强版
- 创建 `enhance_core_tables.py` 核心表快速增强版
- 优化 Prompt，明确禁止思考过程
- 添加响应清理函数，去除 `<think>` 标签等噪音

测试效果：
- 3 个核心表：`t_bz_config_ci_ne_root`、`t_bz_config_customer`、`event_history`
- 处理 155 列，LLM 生成 34 个描述

**SQL Prompt 优化**

```diff
- 【要求】使用JOIN关联多个表
+ 【规则】根据问题复杂度决定是否使用 JOIN（简单查询不需要强制 JOIN）
+ 【规则】直接输出 SQL，不要任何思考过程或解释
```

**验证测试与关键发现**

测试用例 5："上个月上线的新设备有多少"

| 阶段 | 结果 |
|:-----|:-----|
| 向量检索 | ✅ 找到 `t_bz_config_ci_ne_root` |
| Reserve 保护 | ⚠️ 未进入保护列表 |
| LLM 过滤轮次1 | ❌ 被过滤掉（142表→53表）|
| 表召回率 | 0% |

**意外发现：不是 Schema 描述的问题，而是 LinkAlign 的过滤算法缺陷！**

LinkAlign 按列投票判断表是否相关：
```
t_bz_config_ci_ne_root (75列):
  - ONLINE_TIME: 相关 ✅
  - 其他74列: 不相关 ❌
  
投票结果: 1/75 = 1.3%
判定: 过滤掉整个表 ❌
```

应该的逻辑：只要有一个关键列相关 → 保留整表

**技术产出**

- `extract_mysql_schema_enhanced.py` - 全量增强版
- `enhance_core_tables.py` - 核心表快速增强版
- `quick_validate.py` - 单用例快速验证脚本
- `sql_analysis_report.md` - SQL 对比分析报告
- `validation_report.md` - Schema 增强验证报告

**收获与思考**

今天的工作体现了完整的问题解决流程：

1. **问题导向的研究方法**：现象观察 → 初步分析 → 假设提出 → 验证实验 → 推翻假设 → 深入挖掘 → 新假设

2. **学术 vs 工程的差距**：论文关注理想条件下的算法创新，工程需要处理真实世界的复杂性和不完美数据。桥接这个差距需要大量的适配和优化工作。

3. **Schema 增强没有解决问题**：我以为是 Schema 描述缺失导致的，花了 2 个小时实现增强方案，结果发现问题出在更深层的过滤算法逻辑上。这是个很好的教训——要先确认根本原因，再动手实现解决方案。

**下一步计划**

1. **方案 B：核心表白名单**
   - 修改 `batch_test.py` 添加强制保留逻辑
   - 重新运行测试验证效果

2. **如果白名单方案有效**：
   - 全量 Schema 增强（处理剩余 1645 个列）
   - 完整批量测试（7 个用例）

3. **如果效果仍不佳**：
   - 尝试修改 `response_filtering` 投票逻辑
   - 或考虑其他 schema linking 方法

---

## 💭 阶段性感悟

### 关于科研

这是我的第一次算法实习，第一次系统性地阅读 arxiv 论文。我感觉我确实接触到了世界上最先进的东西——这些论文都是刚刚发布的，有些甚至还没来得及放到期刊和顶会。

很多论文确实很厉害，但在我理解之后，我发现它们大多是现有算法的组合与改进，而不是本质上的从无到有的发明。这让我对未来如果要读研究性硕士或者 PhD 有了更真实的认识——科研并不是我之前想象的那样高不可攀。

### 关于学校课程

我之前一直抱怨墨大的课程对找工作没有帮助，因为学校不提供校招，课程内容也感觉离工业界太远。但这次实习中读到的多篇论文——特别是 SteinerSQL 和 SchemaGraphSQL——都使用了图论相关的算法思想。虽然具体的算法可能不一样，但背后的思想——把复杂问题建模成图，用图算法求解——正是墨大图论课程教过的。

原来学校教的东西不是没用，只是当时的我不知道它能用在哪里。

### 关于AI与未来

对比我去年的实习，现在的 AI 强大太多了。我和上个实习的导师聊天时，他说："如果 AI 的发展继续保持两年，之后开发就要被淘汰了。现在 2-3 个开发配合 AI 就能完成一个项目，以后 3 个项目一个开发配合 AI 就足够了。"

AI 的发展让我学习计算机变得非常轻松，它就是一个 24 小时随叫随到的老师。但同时，AI 的发展也在挤压程序员未来的生存空间。

我本来是想走后端开发、全栈开发的路线的，但随着 AI 的发展，我觉得我需要转向 AI 算法相关的方向——不是放弃开发，而是做 AI 项目的开发、AI 算法的工程落地。

我非常感谢能够在本科阶段获得这个算法实习机会。确定这个方向，对我来说非常重要。

---

## 📚 本周论文清单

| 序号 | 论文                                                       | 核心贡献                                                |
| :--: | :--------------------------------------------------------- | :------------------------------------------------------ |
|  1  | **SteinerSQL** (arXiv:2509.19623)                    | 将 Schema Linking 建模为 Steiner Tree 问题，40.04% SOTA |
|  2  | **LinkAlign** (arXiv:2503.18596)                     | 多轮语义增强检索 + Query Rewriting                      |
|  3  | **UNJOIN** (arXiv:2505.18122)                        | 模式简化，将多表扁平化为虚拟大宽表                      |
|  4  | **SchemaGraphSQL** (arXiv:2505.18363)                | 基于图寻路的高效 Schema Linking                         |
|  5  | **CHESS** (arXiv:2405.16755)                         | 多智能体框架，上下文增强                                |
|  6  | **Multi-hop Reasoning with LLMs** (arXiv:2405.09593) | 利用LLM进行多跳推理                                     |
|  7  | **Text-to-SQL Multi-table Join Prediction**          | 多表关联预测与Schema分析                                |
|  8  | **(arXiv:2505.18744)**                               | 检索增强相关方法                                        |

---

## 🎯 下周计划

1. 继续优化 LinkAlign 的检索精度
2. 尝试引入图算法思想进行多表关联推理
3. 整理实验结果，准备下次组会汇报

---

> *"学术界和业界是不一样的——论文写得很漂亮，落地的时候挑战才刚刚开始。"*
