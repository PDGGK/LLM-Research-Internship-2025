# 🚀 实习日志 | 第六周

> **实习时间**：2026年1月4日（周日）- 1月9日（周四）
> **研究方向**：大规模 Schema 下的 Text-to-SQL 多表关联推理
> **指导方向**：AI 算法实习

---

## 📅 第六周工作概览

|  日期  | 核心工作                       | 核心成果                       |
| :----: | :----------------------------- | :----------------------------- |
| 1月5日 | LSH 值匹配 & 温度测试          | MoE 600轮测试 Q1-Q6 100%正确率 |
| 1月6日 | 32B Coder vs MoE 对比          | 两模型各有优劣，准确率均85.7%  |
| 1月8日 | FusionSQL + Deep Research 集成 | 完成 SQL Researcher 端到端流程 |
| 1月9日 | SQL Researcher 调试 + HITL     | 解决阻塞问题 + 人工审核功能    |

---

## 📅 1月5日 周日 | LSH 值匹配实现 & 大规模温度测试

**今日核心成果**

1. 实现 MySQL 兼容的 LSH 值匹配模块，成功构建 35,377 个唯一值的索引
2. 完成 MoE 模型 600 轮大规模温度测试，验证 Q1-Q6 SQL 生成能力 100%

---

### 1. LSH 值匹配模块实现

**背景**: 研究 CHESS 项目的 LSH（Locality Sensitive Hashing）值匹配机制，将其从 SQLite 迁移到 MySQL

**实现内容**:

| 文件                                     | 功能                                       |
| :--------------------------------------- | :----------------------------------------- |
| `fusionsql/value_search/preprocess.py` | 从 MySQL 提取唯一值，构建 MinHash LSH 索引 |
| `fusionsql/value_search/search.py`     | 值搜索器，支持模糊匹配                     |
| `fusionsql/lsh_index/`                 | 预构建的索引文件 (87MB)                    |

**构建结果**:

- 索引表数: 242 张
- 唯一值数: 35,377 个
- 索引大小: lsh.pkl (48MB) + minhashes.pkl (87MB)

**测试验证**:

```
搜索 "Device state" → event_history.EVENT_NAME = 'Device state' ✅
搜索 "ciscoA" → vendor.VENDOR_NAME = 'cisco' (相似度 0.82)
```

**与 TOP10 枚举增强的对比**:

- TOP10: 帮助 LLM 理解列语义（"这个列存的是状态"）
- LSH: 帮助匹配具体的实体值（"ciscoA → cisco"）
- **结论**: 两种方法互补

---

### 2. FusionSQL 项目独立化

**完善 requirements.txt**:

```
FlagEmbedding>=1.0.0   # BGE-M3 模型
openai>=1.0.0          # LLM API
pymysql>=1.0.0         # MySQL 连接
datasketch>=1.6.0      # LSH 模块
tqdm>=4.60.0           # 进度条
numpy>=1.20.0          # 数值计算
```

**与 LinkAlign 的关系**:

- FusionSQL 是 LinkAlign 的精简版，去掉了 llama-index 依赖
- 普通人 `pip install -r requirements.txt` 即可独立运行

---

### 3. MoE 模型大规模温度测试

**测试配置**:

- 温度范围: 0.0, 0.1, 0.2, 0.3, 0.4, 0.5
- 每温度轮数: 100 轮
- 总测试次数: **4,200 次 SQL 生成**

**测试结果**:

| 温度 |  Q1  |  Q2  |  Q3  |  Q4  |  Q5  |  Q6  | Q7 | 平均 |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :-: | :---: |
| 0.0 | 100% | 100% | 100% | 100% | 100% | 100% | 0% | 6.0/7 |
| 0.1 | 100% | 100% | 100% | 100% | 100% | 100% | 0% | 6.0/7 |
| 0.2 | 100% | 100% | 100% | 100% | 100% | 100% | 0% | 6.0/7 |
| 0.3 | 100% | 100% | 100% | 100% | 100% | 100% | 0% | 6.0/7 |
| 0.4 | 100% | 100% | 100% | 100% | 100% | 100% | 0% | 6.0/7 |
| 0.5 | 100% | 100% | 100% | 100% | 100% | 100% | 0% | 6.0/7 |

**核心发现**:

1. **温度对准确率无影响**: 0.0-0.5 全温度一致，标准差=0
2. **Q1-Q6 完美稳定**: 600 轮全部正确
3. **Q7 全部失败**: 模型幻觉 `ALARM_CLEAR_TIME` 列（不存在）

**Q7 失败原因分析**:

- 问题要求"恢复时间"
- `event_history` 表中没有恢复时间字段
- 模型"幻觉"了 `ALARM_CLEAR_TIME` 列
- **结论**: 问题设计缺陷，非模型能力问题

---

### 4. SQL 人工审核

对温度=0 生成的 SQL 进行逐字段分析：

| 题号 | 问题              | SELECT | FROM/JOIN |   WHERE   | 总评 |
| :--: | :---------------- | :----: | :-------: | :-------: | :--: |
|  Q1  | 告警统计          |   ✅   |    ✅    |    ✅    |  ✅  |
|  Q2  | device state down |   ✅   |    ✅    |    ✅    |  ✅  |
|  Q3  | 客户数量          |   ✅   |    ✅    |    ✅    |  ✅  |
|  Q4  | 设备数量          |   ✅   |    ✅    |    ✅    |  ✅  |
|  Q5  | 上月上线          |   ✅   |    ✅    |   ⚠️   | ⚠️ |
|  Q6  | 上月下线          |   ✅   |    ✅    |    ✅    |  ✅  |
|  Q7  | 一周告警          |   ✅   |    ✅    | ❌ 列幻觉 |  ❌  |

---

### 5. 产出文件

| 文件                                           | 说明               |
| :--------------------------------------------- | :----------------- |
| `fusionsql/value_search/`                    | LSH 值匹配模块     |
| `fusionsql/lsh_index/`                       | 预构建的 LSH 索引  |
| `fusionsql/requirements.txt`                 | 完善的依赖列表     |
| `tests/temperature_100rounds_test.py`        | 大规模温度测试脚本 |
| `docs/20260105/temperature_data_analysis.md` | 温度测试分析报告   |
| `docs/20260105/sql_manual_review.md`         | SQL 人工审核报告   |
| `docs/20260105/lsh_test_report.md`           | LSH 测试报告       |

---

## 📅 1月6日 周一 | 32B Coder vs MoE 模型对比测试

**今日核心成果**

完成 Qwen2.5-Coder-32B 与 Qwen3 MoE 模型的 7 题对比测试，发现两模型**准确率相同但失败点不同**。

---

### 1. 总体测试结果

| 模型              | 正确数 | 准确率 |
| :---------------- | :----: | :----: |
| Qwen2.5-Coder-32B |  6/7  | 85.7% |
| Qwen3 MoE         |  6/7  | 85.7% |

**关键发现**: 准确率相同，但失败点完全不同！

---

### 2. 逐题对比

|     题号     | 问题              | 32B | MoE | 差异分析             |
| :----------: | :---------------- | :-: | :-: | :------------------- |
|      Q1      | ciscoA 告警统计   | ✅ | ✅ | 一致                 |
| **Q2** | device state down | ❌ | ✅ | **32B 用错表** |
|      Q3      | 客户数量          | ✅ | ✅ | 一致                 |
|      Q4      | 设备数量          | ✅ | ✅ | 一致                 |
|      Q5      | 上月上线          | ✅ | ✅ | 一致                 |
|      Q6      | 上月下线          | ✅ | ✅ | 一致                 |
| **Q7** | 一周告警+恢复时间 | ✅ | ❌ | **MoE 列幻觉** |

---

### 3. 失败案例深度分析

#### 32B 失败 (Q2) - 表选择错误

**问题**: 列出平台上设备device state down状态超过3个月的设备清单及客户名称

**32B 生成的 SQL**:

```sql
SELECT bci.CUSTOMER_NAME, td.device_name
FROM t_bz_config_customer bci
JOIN t_gn_topo_device td ON bci.CUSTOMER_ID = td.customer_id  -- ❌ 错误表
WHERE td.device_status = 'down' 
    AND td.UPDATE_TIME <= DATE_SUB(NOW(), INTERVAL 3 MONTH);
```

**正确应该用的表**:

- `event_history` (查 Device state down 事件)
- `t_bz_config_ci_ne_root` (设备信息)
- `t_bz_config_customer` (客户信息)

**失败原因**: 32B 选择了 `t_gn_topo_device` 而非 `event_history`，误解了 "device state down" 的含义

---

#### MoE 失败 (Q7) - 列名幻觉

**问题**: 某客户设备近一周内发生过哪些类型的告警？具体告警时间和**恢复时间**分别是什么？

**MoE 生成的 SQL**:

```sql
SELECT e.EVENT_TYPE_NAME, e.EVENT_TIME, 
       e.ALARM_CLEAR_TIME AS recovery_time  -- ❌ 列不存在！
FROM event_history e ...
```

**32B 生成的 SQL**:

```sql
SELECT eh.EVENT_NAME, eh.EVENT_TIME, 
       eh.ACTION_TIME AS 恢复时间  -- ✅ ACTION_TIME 存在
FROM event_history eh ...
```

**差异**:

- MoE 幻觉了 `ALARM_CLEAR_TIME`（不存在）
- 32B 用了 `ACTION_TIME`（存在）

---

### 4. 核心结论

| 维度         | 32B Coder |    MoE    | 评价     |
| :----------- | :--------: | :--------: | :------- |
| 表选择准确性 |  ⭐⭐⭐⭐  | ⭐⭐⭐⭐⭐ | MoE 更准 |
| 列名准确性   | ⭐⭐⭐⭐⭐ |  ⭐⭐⭐⭐  | 32B 更准 |
| Q2 理解      |     ❌     |     ✅     | MoE 更好 |
| Q7 理解      |     ✅     |     ❌     | 32B 更好 |
| 总分         |    6/7    |    6/7    | 平局     |

**优化建议**:

- 需要精确表选择的任务 → 用 MoE
- 需要避免列幻觉的任务 → 用 32B
- **未来方向**: 两个模型可以互补，考虑 ensemble 策略

---

### 5. 产出文件

| 文件                                             | 说明                      |
| :----------------------------------------------- | :------------------------ |
| `docs/20260106/32b_vs_moe_comparison.md`       | 模型对比报告              |
| `docs/20260106/32b_single_test.json`           | 32B 测试结果（含完整SQL） |
| `docs/20260106/32b_temperature_100rounds.json` | 32B 温度测试数据          |

---

## 📅 1月8日 周三 | FusionSQL + Open Deep Research 集成

**今日核心成果**

成功将 FusionSQL 与 Open Deep Research 深度集成，创建 **SQL Researcher** 工作流，实现从自然语言到 SQL 执行再到报告生成的**端到端流程**。

---

### 1. 项目目标

将 FusionSQL（Text-to-SQL 系统）与 Open Deep Research（深度研究代理）整合，创建可以：

1. 接收用户复杂的数据库查询问题
2. 自动拆分成多个子问题
3. 使用 FusionSQL 生成 SQL 并执行
4. 生成结构化的研究报告

---

### 2. 架构设计

```
用户输入复杂问题
    ↓
[clarify_with_user] - 澄清问题（可选）
    ↓
[decompose_question] - 拆分成子问题
    ↓
[sql_research_supervisor] - 调度并行研究
    ↓
[sql_researcher] × N（并行）
    ├─ fusionsql_tool - 生成 SQL（BGE-M3 检索 + LLM）
    └─ execute_sql_tool - 执行 SQL
    ↓
[compress_sql_research] - 压缩结果
    ↓
[final_sql_report] - 生成报告
```

---

### 3. 核心问题与解决方案

#### 问题描述

在使用 vLLM 部署的 Qwen 模型（Qwen2.5-Coder-32B-Instruct）时，发现模型不支持 OpenAI 标准的函数调用（Function Calling）格式。

**症状**:

- `response.tool_calls` 始终为空列表 `[]`
- 工具调用信息被输出到 `response.content` 中

**模型实际输出格式**:

```xml
<tools>
{"name": "conduct_sql_research", "arguments": {"research_topic": "统计客户数量"}}
</tools>
```

#### 解决方案

创建自定义的工具调用解析器 `parse_qwen_tool_calls()`，在模型响应后解析 content 中的工具调用，并注入到 `AIMessage.tool_calls` 中。

**解析器支持格式**:

- `<tools>...</tools>` 标签格式
- `<C>...</C>` 标签格式
- 原始 JSON 格式

---

### 4. 新增代码结构

```
open_deep_research/
  src/
    sql_researcher/                    # 新增包
      __init__.py
      sql_deep_researcher.py           # 主工作流 + 工具调用解析器
      sql_configuration.py             # 配置类
      sql_state.py                     # 状态定义
      sql_prompts.py                   # Prompt 模板
      tools/
        __init__.py
        fusionsql_tool.py              # FusionSQL 工具封装
        sql_executor_tool.py           # SQL 执行工具
```

---

### 5. 关键代码实现

#### FusionSQL 工具封装

```python
@tool(description="将自然语言问题转换为 SQL")
def fusionsql_query(question: str, top_k: int = 10) -> str:
    pipeline = get_fusionsql_pipeline()
    result = pipeline.run_with_details(question, top_k=top_k)
    return f"""
## SQL Query Generated
**Question:** {result['question']}
**Top Retrieved Tables:** {result['retrieved_tables'][:5]}
**Generated SQL:**
```sql
{result['sql']}
```

"""

```

#### SQL 执行工具

```python
@tool(description="执行 SQL 查询")
def execute_sql(sql: str, max_rows: int = 100) -> str:
    # 安全检查 - 只允许 SELECT
    if not sql.strip().upper().startswith("SELECT"):
        return "Error: Only SELECT queries are allowed"
    # 执行查询并返回 Markdown 表格
    ...
```

---

### 6. 端到端测试

**测试问题**: "现在平台上有多少家客户"

**执行流程**:

1. `decompose_question` - 识别为简单问题，无需拆分
2. `sql_supervisor` - 调用 `ConductSQLResearch` 工具
3. `sql_researcher` - 调用 `fusionsql_query` 生成 SQL
4. `sql_researcher` - 调用 `execute_sql` 执行查询
5. `final_sql_report` - 生成最终报告

**生成的 SQL**:

```sql
SELECT COUNT(*) FROM t_bz_config_customer;
```

**查询结果**: 150 家客户

---

### 7. 产出文件

| 文件                                                   | 说明                  |
| :----------------------------------------------------- | :-------------------- |
| `open_deep_research/src/sql_researcher/`             | SQL Researcher 完整包 |
| `docs/20260108/sql_researcher_integration_report.md` | 集成技术报告          |
| `docs/20260108/test_sql_researcher_7q.py`            | 7题测试脚本           |
| `docs/20260108/sql_researcher_7q_test_result.json`   | 测试结果              |

---

## 📅 1月9日 周四 | SQL Researcher 调试与优化

**今日核心成果**

解决 SQL Researcher 中的 LangGraph 阻塞检测问题和 JSON 解析问题，**7题测试从 0% 提升到 85.7%**！

---

### 1. 问题诊断

在 SQL Researcher 7 题测试中，初始结果为 **0/7 通过**。生成的 SQL 使用了错误的表名（如 `customers`, `devices`），而不是数据库中实际的表。

#### 排查过程

| 检查项                  | 状态 | 结论                                      |
| ----------------------- | ---- | ----------------------------------------- |
| FusionSQL 代码          | ✅   | Git 状态干净，无修改                      |
| FusionSQL Pipeline      | ✅   | 独立测试正确返回 `t_bz_config_customer` |
| fusionsql_query 工具    | ✅   | 返回正确 SQL                              |
| parse_qwen_tool_calls() | ✅   | 正确解析 Qwen 工具调用格式                |

---

### 2. 根本原因

**LangGraph 的阻塞调用检测**导致 `fusionsql_query` 返回错误信息而非 SQL：

```
[DEBUG] Result preview: '错误: Blocking call to os.getcwd
Heads up! LangGraph dev identified a synchronous blocking call in your code...'
```

问题在于 FusionSQL 的依赖库（BGE-M3/FlagEmbedding）调用了同步阻塞函数。

---

### 3. 解决方案

#### 3.1 ThreadPoolExecutor 包装

使用 `ThreadPoolExecutor` 在单独线程中执行 FusionSQL，绕过 LangGraph 阻塞检测：

```python
# fusionsql_tool.py
with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
    future = executor.submit(_run_pipeline, question, top_k)
    result = future.result(timeout=120)
```

#### 3.2 修复 JSON 解析器

Qwen 的工具调用输出嵌入在中文文本中，简单正则无法处理嵌套 `{}`，改用括号计数算法提取 JSON。

#### 3.3 强化 Prompt

```python
# 修改后
## ⚠️ 重要规则
1. 必须先调用 fusionsql_query
2. 禁止自己编造表名
3. 收到结果后立即调用 execute_sql
4. 不要说 "there was an issue"
```

---

### 4. 修复效果

| 测试阶段           | 结果                     |
| ------------------ | ------------------------ |
| 原始               | 0/7 (0%)                 |
| 第一次修复         | 3/7 (42.9%)              |
| **最终修复** | **6/7 (85.7%)** ✅ |

**通过的问题**:

- ✅ 设备ciscoA告警统计
- ✅ 现在平台上有多少家客户
- ✅ 现在平台上有多少台设备
- ✅ 上个月上线的新设备有多少
- ✅ 上个月下线的设备有多少
- ✅ 某客户设备近一周内告警

**仍需改进**:

- ⚠️ 设备device state down超3个月清单（超时）

---

### 5. 修改的文件

| 文件                                       | 修改内容                      |
| ------------------------------------------ | ----------------------------- |
| `sql_researcher/tools/fusionsql_tool.py` | ThreadPoolExecutor 包装       |
| `sql_researcher/sql_deep_researcher.py`  | 强制工具链 + 修复 JSON 解析器 |
| `sql_researcher/sql_prompts.py`          | 强化 Prompt                   |

---

### 6. 产出文件

| 文件                                             | 说明           |
| :----------------------------------------------- | :------------- |
| `docs/20260109/sql_researcher_debug_report.md` | 调试阶段性报告 |

---

### 7. Human-in-the-Loop 问题拆解审核功能

**功能目标**: 让用户能够在系统自动拆解问题后审核和修改子问题，确保拆解结果符合预期。

#### 7.1 LangGraph interrupt 机制

研究了 LangGraph 的 `interrupt()` 函数实现人机交互：

```python
from langgraph.types import interrupt

# 在节点中调用，图会暂停等待外部 resume
user_feedback = interrupt("请确认问题拆解是否正确")
```

#### 7.2 初始实现问题

**问题**: 将 `interrupt` 放在 `decompose_question` 节点内部，用户反馈后重新分解，但结果完全一样。

**根因**: LangGraph 的 `interrupt` 后，每次 resume 创建新 run，状态无法在同一节点的多次 `interrupt` 间保持。

#### 7.3 参考 Legacy 代码重构

研究 `legacy/graph.py` 的 `human_feedback` 节点，发现正确架构：

```
# legacy 架构
generate_report_plan → human_feedback → (确认) → build_section
                              ↓
                         (反馈) → generate_report_plan (读取 feedback 状态)
```

#### 7.4 最终实现

将 `decompose_question` 拆分为两个独立节点：

```
decompose_question → review_decomposition → (确认) → sql_research_supervisor
                              ↓
                         (反馈) → decompose_question (读取 feedback)
```

**代码修改**:

| 文件 | 修改内容 |
|:-----|:---------|
| `sql_deep_researcher.py` | 新增 `review_decomposition` 节点处理人工审核 |
| `sql_state.py` | `decomposition_feedback` 改为 `List[str]` 类型 |
| `sql_configuration.py` | 添加 `enable_decomposition_review` 配置项 |

#### 7.5 测试验证

**测试案例**: 7个问题合并成的复杂自然语言输入

| 阶段 | 子问题数量 | 说明 |
|:-----|:----------:|:-----|
| 第一次拆解 | 7 个 | 系统自动拆解 |
| 用户反馈 | - | "最多5个问题,down状态相关的可以合并" |
| 第二次拆解 | **4 个** ✅ | 成功按反馈修改 |
| 确认执行 | - | 用户输入 'yes' |
| 最终报告 | ✅ | 正确生成完整报告 |

**效果示例**:

```
# 第一次拆解 (7个)
1. 平台上的客户数量是多少？
2. 平台上的设备数量是多少？
3. 上个月有多少设备上线？
4. 上个月有多少设备下线？
5. 查询所有设备状态为down的记录
6. 筛选状态持续超过3个月的设备
7. 关联客户信息获取客户名称

# 用户反馈: "最多5个问题,down状态相关的可以合并"

# 第二次拆解 (4个) ✅
1. 查询平台上的客户数量
2. 查询平台上的设备数量
3. 查询上个月设备的上下线情况
4. 查询设备状态为down超过3个月的设备及其所属客户  ← 合并了5,6,7
```

#### 7.6 HITL 产出文件

| 文件                                             | 说明               |
| :----------------------------------------------- | :----------------- |
| `docs/20260109/hitl_implementation_report.md`  | HITL 功能设计文档  |
| `docs/20260109/hitl_test_report.md`            | 完整测试报告       |
| `docs/20260109/interactive_hitl_test.py`       | 交互式测试脚本     |
| `docs/20260109/internship_log_2026-01-09.md`   | 详细开发日志       |

---

## 📊 第六周总结

### 核心成果

| 成果                 | 详情                                 |
| :------------------- | :----------------------------------- |
| 1️⃣ LSH 值匹配     | MySQL 兼容，35,377 唯一值索引        |
| 2️⃣ 温度测试       | 4,200次测试验证0.0-0.5温度无影响     |
| 3️⃣ 模型对比       | 32B/MoE 各有优劣，互补可行           |
| 4️⃣ SQL Researcher | FusionSQL + Deep Research 端到端集成 |
| 5️⃣ 调试修复       | 解决 LangGraph 阻塞问题，7题85.7%    |
| 6️⃣ **HITL 功能** | **Human-in-the-Loop 问题拆解审核**   |

### 技术亮点

1. **ThreadPoolExecutor 绕过阻塞检测** - 解决 LangGraph 与同步库的兼容问题
2. **自定义工具调用解析器** - 适配 Qwen 模型的非标准输出格式
3. **括号计数 JSON 提取算法** - 处理嵌套在中文文本中的 JSON
4. **LangGraph interrupt 机制** - 实现人机交互问题拆解审核（独立节点架构）

### 下一步计划

| 优先级 | 任务                                 |
| :----- | :----------------------------------- |
| P0     | 优化 Q2（device state down）超时问题 |
| P1     | 完善 SQL Researcher 错误处理         |
| P2     | 探索 32B + MoE ensemble 策略         |

---

*日志更新日期: 2026-01-09*
*本周核心成果: FusionSQL + Open Deep Research 深度集成，SQL Researcher 7题测试达85.7%*
